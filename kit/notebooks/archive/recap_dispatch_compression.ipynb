{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074eec2-00cc-4ec8-a6bf-befe2effa642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import sys\n",
    "from new_modeling_toolkit.common.asset.plant import ResourceCategory\n",
    "from new_modeling_toolkit.recap.recap_case import RecapCase\n",
    "import new_modeling_toolkit.recap.updated_dispatch_model as dispatch_model\n",
    "from new_modeling_toolkit.recap.updated_dispatch_model import _divide_monte_carlo_draws_into_subproblems, _compress_dispatch_subproblem_data, _construct_and_solve_dispatch_subproblem, UpdatedDispatchModel\n",
    "from new_modeling_toolkit.utils.parallelization_utils import parallelize\n",
    "from new_modeling_toolkit.utils.pyomo_utils import convert_pyomo_object_to_dataframe\n",
    "from new_modeling_toolkit.common.util import DirStructure\n",
    "\n",
    "import pyomo.environ as pyo\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4125a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(dispatch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb48d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42de72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_str = DirStructure(code_dir=Path(\"../new_modeling_toolkit/\"), data_folder=\"data\", model_name=\"recap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cd61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "recap_case = RecapCase.from_dir(dir_str=dir_str, case_name=\"WALC_speedup_challenge_EUE\", gurobi_credentials=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_capacity = 0\n",
    "\n",
    "# Divide Monte Carlo draws into N-year long subproblems\n",
    "data_by_draw_and_subproblem = _divide_monte_carlo_draws_into_subproblems(recap_case.monte_carlo_draws)\n",
    "\n",
    "# Get inputs to compression\n",
    "compress_subproblem_data_kwargs = [\n",
    "    dict(\n",
    "        draw_name=draw_name,\n",
    "        subproblem_number=subproblem_number,\n",
    "        subproblem_data=subproblem_data,\n",
    "        perfect_capacity=perfect_capacity,\n",
    "    )\n",
    "    for draw_name, subproblem_number, subproblem_data in data_by_draw_and_subproblem\n",
    "]\n",
    "\n",
    "# Compress subproblem data\n",
    "dispatch_model_data_list = parallelize(\n",
    "    _compress_dispatch_subproblem_data,\n",
    "    kwargs_list=compress_subproblem_data_kwargs,\n",
    "    progress_bar_description=\"Subproblem Compression\",\n",
    "    num_processes=min(len(compress_subproblem_data_kwargs), 20),\n",
    ")\n",
    "\n",
    "# Construct and solve compressed dispatch subproblems\n",
    "dispatch_model_kwargs = [\n",
    "    dict(\n",
    "        draw_name=draw_name,\n",
    "        subproblem_number=subproblem_number,\n",
    "        dispatch_model_data=dispatch_model_data,\n",
    "        dispatch_objective=recap_case.case_settings.dispatch_objective,\n",
    "    )\n",
    "    for draw_name, subproblem_number, dispatch_model_data in dispatch_model_data_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2740632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dispatch_model_kwargs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_model_data = args[\"dispatch_model_data\"]\n",
    "dispatch_objective = args[\"dispatch_objective\"]\n",
    "\n",
    "construction_start = time.time()\n",
    "dispatch_model_ = UpdatedDispatchModel(\n",
    "    dispatch_model_data=dispatch_model_data,\n",
    "    objective_fn=dispatch_objective,\n",
    ")\n",
    "construction_end = time.time()\n",
    "\n",
    "print(construction_end - construction_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b5661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_start = time.time()\n",
    "solution = dispatch_model_.solve(solver_name=\"gurobi\")\n",
    "solve_end = time.time()\n",
    "\n",
    "print(solve_end - solve_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fcfee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_model_._create_dispatch_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_dispatch_dataframe(self) -> pd.DataFrame:\n",
    "    \"\"\"Creates a data frame containing dispatch information for each timestamp.\n",
    "\n",
    "    Returns:\n",
    "        dispatch_df: the data frame with dispatch information\n",
    "    \"\"\"\n",
    "    # Get dispatch results for all resources\n",
    "    Increase_Load_MW = convert_pyomo_object_to_dataframe(self.Increase_Load_MW)\n",
    "    Provide_Power_MW = convert_pyomo_object_to_dataframe(self.Provide_Power_MW)\n",
    "    Provide_Reserve_MW = convert_pyomo_object_to_dataframe(self.Provide_Reserve_MW)\n",
    "\n",
    "    dispatch_results_by_resource = pd.concat([Increase_Load_MW, Provide_Power_MW, Provide_Reserve_MW], axis=1)\n",
    "\n",
    "    dispatch_results_by_group = pd.concat(\n",
    "        [\n",
    "            dispatch_results_by_resource.loc[pd.IndexSlice[list(group), :], :]\n",
    "            .groupby(self.DISPATCH_HOURS.name)\n",
    "            .sum()\n",
    "            .rename(columns=lambda col: f\"{group_name}_{col}\")\n",
    "            for group_name, group in [\n",
    "                (\"Storage\", self.STORAGE_RESOURCES),\n",
    "                (\"Hydro\", self.HYDRO_RESOURCES),\n",
    "                (\"DR\", self.DR_RESOURCES),\n",
    "            ]\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Create dispatch dataframe\n",
    "    dispatch_df = pd.concat(\n",
    "        {\n",
    "            \"unserved_energy\": convert_pyomo_object_to_dataframe(self.Unserved_Energy).squeeze(),\n",
    "            \"unserved_reserve\": convert_pyomo_object_to_dataframe(self.Unserved_Reserve).squeeze(),\n",
    "            \"net_load\": convert_pyomo_object_to_dataframe(self.Net_Load).squeeze(),\n",
    "            \"operating_reserve\": convert_pyomo_object_to_dataframe(self.Operating_Reserve).squeeze(),\n",
    "        },\n",
    "        axis=1,\n",
    "    )\n",
    "    dispatch_df = pd.concat([dispatch_df, dispatch_results_by_group], axis=1)\n",
    "    dispatch_df.loc[:, \"perfect_capacity\"] = pyo.value(self.Perfect_Capacity_MW)\n",
    "    dispatch_df.loc[:, \"unserved_energy_and_reserve\"] = dispatch_df.loc[\n",
    "        :, [\"unserved_energy\", \"unserved_reserve\"]\n",
    "    ].sum(axis=1)\n",
    "\n",
    "    # Upsample to original (full) length of subproblem\n",
    "    dispatch_df_full = pd.DataFrame(index=self.all_hours)\n",
    "    dispatch_df_full = dispatch_df_full.join(dispatch_df)\n",
    "    dispatch_df_full[[\"unserved_energy\", \"unserved_reserve\", \"unserved_energy_and_reserve\"]] =\\\n",
    "        dispatch_df_full[[\"unserved_energy\", \"unserved_reserve\", \"unserved_energy_and_reserve\"]].fillna(0)\n",
    "\n",
    "    # Set index\n",
    "    dispatch_df_full = dispatch_df_full.reset_index(drop=True).set_index(self.all_timestamps)\n",
    "    dispatch_df_full.index.name = dispatch_model._NET_LOAD_TIMESTAMP_INDEX_NAME\n",
    "    \n",
    "    return dispatch_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b63283",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_results = _create_dispatch_dataframe(dispatch_model_)\n",
    "dispatch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_results.loc[(dispatch_results[\"Storage_Provide_Power_MW\"] > 0) | (dispatch_results[\"Storage_Increase_Load_MW\"] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549bf2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_results[[\"unserved_energy\", \"unserved_reserve\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7190fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_results[\"net_load\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1597fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad87ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dispatch_model_kwargs[0]\n",
    "subproblem_results = _construct_and_solve_dispatch_subproblem(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97490c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_model_data = args[\"dispatch_model_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ab6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_model_.all_hours = dispatch_model_data.all_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c6046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d019e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadce358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822a3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b230e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c430fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f16539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from pydantic import Field\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2680839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(BaseModel):\n",
    "    \n",
    "    field1: int\n",
    "    field2: int\n",
    "    field3: int = Field(freq=\"M\")\n",
    "    \n",
    "    d1: dict\n",
    "    d2: dict\n",
    "    #_d: Optional[dict]\n",
    "        \n",
    "    @property\n",
    "    def d(self):\n",
    "        return {**self.d1, **self.d2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7c1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Test(\n",
    "    field1=1,\n",
    "    field2=2,\n",
    "    field3=3,\n",
    "    d1={\"a\": 1}, \n",
    "    d2={\"b\": 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343dd1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "{**t.d1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {\"a\": {1: 10, 2: 12, 3: 9}, \"b\": {1: 14, 2: 16, 3: 19}}\n",
    "\n",
    "d2 = {\"c\": {1: 10, 2: 12, 3: 9}, \"d\": {1: 10, 2: 12, 3: 9}}\n",
    "\n",
    "d = {**d1, **d2}\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22660c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {i: f for i, f in zip(np.arange(100000), np.random.rand(100000))}\n",
    "d2 = {i: f for i, f in zip(np.arange(100000, 200000), np.random.rand(100000))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb9698-afd4-4b7b-99c9-f408a0c8bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.remove()\n",
    "logger.add(sys.stdout, level=\"WARNING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b7a53-b63a-4cf0-a2af-c05e6cc236d0",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "\n",
    "* Find all continuous periods with net load >= 0\n",
    "\n",
    "* Apply a buffer period to start and end of each window (1 week for now)\n",
    "\n",
    "* Group all windows together that are separated by less than desired (2 weeks for now)\n",
    "\n",
    "* Determine which window should be the \"first\" window, by finding the earliest window with sufficient lead time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15f73f4-aecd-4996-9bd7-3f6a1eac8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_START_DATETIME_COLNAME = \"start_datetime\"\n",
    "_END_DATETIME_COLNAME = \"end_datetime\"\n",
    "_PERIOD_ID = \"period_id\"\n",
    "_DISPATCH_PROBLEM_ID = \"dispatch_problem_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36903054-10c4-49f4-a400-f17427891ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_PERIOD_START_BUFFER = pd.Timedelta(hours=-168)\n",
    "_PERIOD_END_BUFFER = pd.Timedelta(hours=168)\n",
    "_PERIOD_MIN_SEPARATION_WINDOW = pd.Timedelta(hours=168*2)\n",
    "_PERIOD_MIN_LEAD_WINDOW = pd.Timedelta(hours=168*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069824a-6438-44f6-987b-3bf641492720",
   "metadata": {},
   "source": [
    "# Create Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009b6f6-2067-416e-a296-2fea697f5967",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Old: Fake Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2681696-3cf5-40dc-82e9-12621f2b4641",
   "metadata": {},
   "source": [
    "### Raw Negative Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee48bad-8b6e-4860-a7f4-c56d1165da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_index_raw = pd.date_range(start=\"2010-01-01 00:00\", end=\"2020-01-01 00:00\", inclusive=\"left\", freq=\"H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bbbc1a-7a53-4e4c-8e73-0d6eaf20aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_series_raw = pd.Series(index=dt_index_raw, data=-1.0, name=\"net_load\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436e5eb6-f202-4050-bc11-691dd2c7a359",
   "metadata": {},
   "source": [
    "### Remove Leap Days\n",
    "\n",
    "To verify that the code works without leap days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054cfbf5-f20d-4355-8a6d-943418340730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_raw = pd.concat({\"MC_draw_1\": neg_series_raw, \"MC_draw_2\": neg_series_raw}, axis=0, names=(\"MC_draw\", \"timestamp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488a11a5-ae79-470a-969b-109df546ab77",
   "metadata": {},
   "source": [
    "### Remove Leap Days\n",
    "\n",
    "To verify that the code works without leap days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5268b0-73e7-402a-a8ab-284c141c8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_raw = input_raw.loc[~((input_raw.index.get_level_values(\"timestamp\").month == 2) & (input_raw.index.get_level_values(\"timestamp\").day == 29))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c636b96d-5188-44ce-a8ea-6637b8642fea",
   "metadata": {},
   "source": [
    "### Define Positive-Net-Load Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6062ed-7494-4c56-8f93-3be8062da3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = input_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb57507-0a66-4dac-8827-8f696229b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data.loc[pd.IndexSlice[\"MC_draw_1\", \"2013-03-10 06:00\":\"2013-03-12 19:00\"]] = 5.0\n",
    "# input_data.loc[pd.IndexSlice[\"MC_draw_1\", \"2014-07-24 04:00\":\"2014-07-29 22:00\"]] = 5.0\n",
    "# input_data.loc[pd.IndexSlice[\"MC_draw_1\", \"2014-08-12 07:00\":\"2014-08-15 15:00\"]] = 5.0\n",
    "# input_data.loc[pd.IndexSlice[\"MC_draw_1\", \"2018-05-04 00:00\"]] = 5.0\n",
    "# input_data.loc[pd.IndexSlice[\"MC_draw_1\", \"2018-06-12 10:00\":\"2018-06-12 12:00\"]] = 5.0\n",
    "# input_data.loc[pd.IndexSlice[\"MC_draw_1\", \"2018-06-18 10:00\":\"2018-06-18 12:00\"]] = 5.0\n",
    "# input_data.loc[pd.IndexSlice[\"MC_draw_2\", \"2017-01-01 09:00\":\"2017-01-02 14:00\"]] = 5.0\n",
    "# input_data.loc[pd.IndexSlice[\"MC_draw_2\", \"2017-01-18 02:00\":\"2017-01-18 10:00\"]] = 5.0\n",
    "# input_data.loc[pd.IndexSlice[\"MC_draw_2\", \"2017-12-24 13:00\":\"2017-12-26 12:00\"]] = 5.0\n",
    "# input_data.loc[pd.IndexSlice[\"MC_draw_2\", \"2018-04-24 13:00\":\"2018-04-25 12:00\"]] = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1736aa-7b9a-4095-9ee8-ed8895270f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data.index = pd.MultiIndex.from_arrays([input_data.index.get_level_values(0), input_data.index.get_level_values(1).year, input_data.index.get_level_values(1)], names=(\"MC_draw\", \"year\", \"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb5d31-d4e5-4a93-a8d7-289a9058ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab630a6-5ee2-4517-980b-ac7096b3ce21",
   "metadata": {},
   "source": [
    "## New: Use MC Draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca28d13-30cd-4f2f-a657-e9b4dbc67e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_str = DirStructure(code_dir=Path(\"../new_modeling_toolkit/\"), data_folder=\"data\", model_name=\"recap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde205a-1554-4f2f-a071-f5a80be42762",
   "metadata": {},
   "outputs": [],
   "source": [
    "recap_case = RecapCase.from_dir(dir_str=dir_str, case_name=\"WALC_speedup_benchmark_EUE\", gurobi_credentials=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9f9fc6-aaf7-4654-bdaa-15271fea3ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.concat({draw_id: draw.net_load for draw_id, draw in recap_case.monte_carlo_draws.items()}, axis=0, names=(\"MC_draw\", \"timestamp\")).rename(\"net_load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f898e04-d01c-4fb3-a315-77f274ea4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.index = pd.MultiIndex.from_arrays([input_data.index.get_level_values(0), (input_data.index.get_level_values(1).year - input_data.index.get_level_values(1).year.min()) // 12, input_data.index.get_level_values(1)], names=(\"MC_draw\", \"subproblem_ID\", \"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff2990-d1b7-46ca-94aa-2eeb671ca117",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6862b6b-b577-4bcd-8c17-7dd68dedcff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search interval upper/lower bounds\n",
    "UB = max(recap_case.monte_carlo_draws[\"MC_draw_0\"].load + recap_case.monte_carlo_draws[\"MC_draw_0\"].reserves)\n",
    "LB = -UB\n",
    "\n",
    "logger.debug(f\"Initial Lower Bound: {LB:.2f} MW\")\n",
    "logger.debug(f\"Initial Upper Bound: {UB:.2f} MW\")\n",
    "\n",
    "# Define reliability as function of perfect capacity when ELRs are effectively removed from system\n",
    "def reliability_func_no_ELRs(perfect_capacity):\n",
    "    unserved_energy_and_reserve = recap_case.run_dispatch_no_ELRs(perfect_capacity=perfect_capacity)\n",
    "    reliability = recap_case.calculate_reliability(unserved_energy_and_reserve, metric=\"EUE\")\n",
    "    return reliability\n",
    "\n",
    "# Use bisection method to get perfect capacity shortfall lower and upper bounds\n",
    "perfect_capacity_UB = recap_case.bisection_method(\n",
    "    reliability_func=reliability_func_no_ELRs, target=0.1, LB=LB, UB=UB\n",
    ")\n",
    "perfect_capacity_LB = perfect_capacity_UB - recap_case.ELR_capacity  # ELR ELCC upper bound is 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d001d04-d6a7-4ac8-bf78-43fed01ae124",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_capacity_UB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d10dc4-0231-4e2f-b5d1-831c4110969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_capacity_LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75c488-3a7b-4d55-9024-668f88439418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = input_data - perfect_capacity_LB\n",
    "#input_data = input_data + 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab77a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9d6f72-1b02-45ed-8b54-dce4ccaf6c61",
   "metadata": {},
   "source": [
    "# Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69374347",
   "metadata": {},
   "outputs": [],
   "source": [
    "_PERIOD_START_BUFFER = pd.Timedelta(hours=-168)\n",
    "_PERIOD_END_BUFFER = pd.Timedelta(hours=168)\n",
    "_PERIOD_MIN_SEPARATION_WINDOW = pd.Timedelta(hours=168*2)\n",
    "_PERIOD_CONSECUTIVE_DELTA = pd.Timedelta(hours=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ac1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subproblems = _divide_monte_carlo_draws_into_subproblems(recap_case.monte_carlo_draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cebe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subproblem = subproblems[0]\n",
    "subproblem_data_dict = subproblem[2]\n",
    "net_load = subproblem_data_dict[\"net_load\"]\n",
    "\n",
    "perfect_capacity = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2963f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charlie's second attempt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# We just need a list of dates that are \"in\" and \"out\", and then label them by adjacency in the final step\n",
    "\n",
    "net_load = net_load - perfect_capacity\n",
    "\n",
    "# Get single subproblem\n",
    "timesteps = net_load.index\n",
    "dates = np.unique(timesteps.date)\n",
    "span = dates.max() - dates.min()\n",
    "\n",
    "# Get positive net load dates\n",
    "pos_timesteps = timesteps[net_load.values > 0]\n",
    "pos_dates = np.unique(pos_timesteps.date)\n",
    "\n",
    "# Loop through pos_dates to get in dates\n",
    "in_dates = pd.DatetimeIndex([]) # Initialize\n",
    "\n",
    "# Add +/- 1 week buffer\n",
    "for date in pos_dates:\n",
    "    \n",
    "    if date <= in_dates.max().date():\n",
    "        #print(\"skipping \", date)\n",
    "        continue\n",
    "\n",
    "    start, end = max(date + _PERIOD_START_BUFFER, dates.min()), min(date + _PERIOD_END_BUFFER, dates.max())\n",
    "    window_dates = pd.date_range(start, end, freq=\"D\")\n",
    "    in_dates = in_dates.union(window_dates)\n",
    "    \n",
    "# For testing edge case of dispatch window crossing boundary of loop\n",
    "#in_dates = in_dates.insert(0, pd.Timestamp(year=1979, month=1, day=10))\n",
    "#in_dates = in_dates.insert(-1, pd.Timestamp(year=1990, month=12, day=30))\n",
    "\n",
    "# Consolidate windows < 2 weeks apart\n",
    "in_dates = in_dates.sort_values()\n",
    "i = 0   \n",
    "while i < len(in_dates) - 1:\n",
    "    start, end = in_dates[i], in_dates[i+1]\n",
    "    time_delta = end - start\n",
    "    if (time_delta > _PERIOD_CONSECUTIVE_DELTA) and (time_delta < _PERIOD_MIN_SEPARATION_WINDOW): # non-consecutive dates < 2 weeks apart\n",
    "        #print(f\"Consolidating {start} through {end}\")\n",
    "        window_dates = pd.date_range(start, end, freq=\"D\")\n",
    "        in_dates = in_dates.union(window_dates)\n",
    "    i += 1\n",
    "        \n",
    "# Use modular arithmetic to consolidate first and last periods if < 2 weeks apart in \"loop\"\n",
    "start, end = in_dates[-1], in_dates[0]\n",
    "time_delta = end - start\n",
    "time_delta = pd.Timedelta(seconds=np.mod(time_delta.total_seconds(), span.total_seconds()))\n",
    "if (time_delta < _PERIOD_MIN_SEPARATION_WINDOW):\n",
    "    #print(f\"Consolidating {start} through {end}\")\n",
    "    window_dates = pd.date_range(start, dates.max(), freq=\"D\")\n",
    "    in_dates = in_dates.union(window_dates)\n",
    "    window_dates = pd.date_range(dates.min(), end, freq=\"D\")\n",
    "    in_dates = in_dates.union(window_dates)\n",
    "\n",
    "# Label windows\n",
    "df_in = pd.DataFrame(index=pd.DatetimeIndex(dates))\n",
    "df_in.loc[in_dates, \"in\"] = 1\n",
    "df_in = df_in.fillna(0)\n",
    "df_in[\"label\"] = (df_in.shift(1) > df_in).cumsum() + 1\n",
    "\n",
    "# Join period after last window with first window\n",
    "df_in.loc[df_in[\"label\"] == df_in[\"label\"].max(), \"label\"] = df_in[\"label\"].min()\n",
    "\n",
    "# Re-sample at hourly frequency\n",
    "df_in.loc[df_in.index[-1] + pd.Timedelta(hours=24)] = df_in.loc[df_in.index[-1]]\n",
    "df_in = df_in.resample(\"H\").ffill()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_to_hour_mapping = {ts: i for i, ts in enumerate(df_in.index)}\n",
    "timestamp_to_day_mapping = {ts: i for i, ts in enumerate(df_in.index.to_period(\"D\").to_timestamp().unique())}\n",
    "timestamp_to_month_mapping = {ts: i for i, ts in enumerate(df_in.index.to_period(\"M\").to_timestamp().unique())}\n",
    "timestamp_to_year_mapping = {ts: i for i, ts in enumerate(df_in.index.to_period(\"Y\").to_timestamp().unique())}\n",
    "\n",
    "df_in = df_in[[\"in\"]]\n",
    "\n",
    "df_in[\"hour\"] = range(len(df_in))\n",
    "df_in[\"day\"] = list(timestamp_to_day_mapping[ts] for ts in df_in.index.to_period(\"D\").to_timestamp())\n",
    "df_in[\"month\"] = list(timestamp_to_month_mapping[ts] for ts in df_in.index.to_period(\"M\").to_timestamp())\n",
    "df_in[\"year\"] = list(timestamp_to_year_mapping[ts] for ts in df_in.index.to_period(\"Y\").to_timestamp())\n",
    "\n",
    "df_in_sub = df_in.loc[df_in[\"in\"] == 1, [\"hour\", \"day\", \"month\", \"year\"]]\n",
    "\n",
    "df_daily = df_in_sub.groupby(\"day\")\n",
    "days = list(df_daily.groups.keys())\n",
    "day_to_hour_mapping = {d: list(df_daily.get_group(d)[\"hour\"].values) for d in days}\n",
    "\n",
    "df_monthly = df_in_sub.groupby(\"month\")\n",
    "months = list(df_monthly.groups.keys())\n",
    "month_to_hour_mapping = {m: list(df_monthly.get_group(m)[\"hour\"].values) for m in months}\n",
    "\n",
    "df_annual = df_in_sub.groupby(\"year\")\n",
    "years = list(df_annual.groups.keys())\n",
    "year_to_hour_mapping = {y: list(df_annual.get_group(y)[\"hour\"].values) for y in years}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4300dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_to_hour_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_in_hourly.groupby(df_in_hourly.index.to_period(\"D\").to_timestamp()).groups\n",
    "day_to_hour_mapping = {timestamp_to_day_mapping.loc[group]: list(timestamp_to_hour_mapping.loc[groups[group]].values) for group in groups}\n",
    "\n",
    "groups = df_in_hourly.groupby(df_in_hourly.index.to_period(\"M\").to_timestamp()).groups\n",
    "month_to_hour_mapping = {timestamp_to_month_mapping.loc[group]: list(timestamp_to_hour_mapping.loc[groups[group]].values) for group in groups}\n",
    "\n",
    "groups = df_in_hourly.groupby(df_in_hourly.index.to_period(\"Y\").to_timestamp()).groups\n",
    "year_to_hour_mapping = {timestamp_to_year_mapping.loc[group]: list(timestamp_to_hour_mapping.loc[groups[group]].values) for group in groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6c9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc967b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de33ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.loc[df_in[\"in\"] == 1, \"hour\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfc321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in[\"label\"].plot()\n",
    "(df_in[\"label\"] * df_in[\"in\"]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96575bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust hydro budgets\n",
    "\n",
    "hydro_pmin = subproblem_data_dict[\"hydro_pmin\"]\n",
    "hydro_pmin_out = hydro_pmin.multiply((1 - df_in[\"in\"]).values, axis=0)\n",
    "\n",
    "hydro_pmin_out_monthly = hydro_pmin_out.groupby([hydro_pmin_out.index.to_period(\"M\").to_timestamp()]).sum()\n",
    "hydro_budget_monthly = subproblem_data_dict[\"hydro_budget_monthly\"]\n",
    "hydro_budget_monthly_adjusted = hydro_budget_monthly - hydro_pmin_out_monthly\n",
    "subproblem_data_dict[\"hydro_budget_monthly\"] = hydro_budget_monthly_adjusted\n",
    "\n",
    "hydro_pmin_out_annual = hydro_pmin_out.groupby([hydro_pmin_out.index.to_period(\"Y\").to_timestamp()]).sum()\n",
    "hydro_budget_annual = subproblem_data_dict[\"hydro_budget_annual\"]\n",
    "hydro_budget_annual_adjusted = hydro_budget_annual - hydro_pmin_out_annual\n",
    "subproblem_data_dict[\"hydro_budget_annual\"] = hydro_budget_annual_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fc8f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate storage initial SOC for each dispatch window\n",
    "\n",
    "# Get available energy profile\n",
    "available_energy = - net_load + perfect_capacity + hydro_pmin_out.sum(axis=1)\n",
    "\n",
    "# Get storage pmax and SOC max\n",
    "storage_pmax = subproblem_data_dict[\"storage_pmax\"]\n",
    "storage_SOC_max = subproblem_data_dict[\"storage_soc_max\"]\n",
    "storage_data_dict = subproblem_data_dict[\"storage_data_dict\"]\n",
    "\n",
    "# Sort storage resources by duration (ignore \"inf\")\n",
    "durations = (storage_pmax.max(axis=0) / storage_SOC_max.max(axis=0)).replace(np.inf, np.nan).dropna().sort_values()\n",
    "\n",
    "# Define dictionary of time series\n",
    "timeseries = {\n",
    "    \"df_in\": df_in,\n",
    "    \"available_energy\": available_energy,\n",
    "    \"storage_pmax\": storage_pmax,\n",
    "    \"storage_SOC_max\": storage_SOC_max,\n",
    "}\n",
    "\n",
    "# Re-order time series by dispatch window label\n",
    "first_window = df_in[\"label\"].min()\n",
    "last_window = df_in[\"label\"].max()\n",
    "loop_inds = (df_in[\"label\"] == first_window) & (df_in.index > max(df_in.loc[df_in[\"label\"] == last_window].index))\n",
    "for ts in timeseries.keys():\n",
    "    #print(ts)\n",
    "    df_ts = timeseries[ts]\n",
    "    df_ts = pd.concat([df_ts[loop_inds], df_ts[~loop_inds]])\n",
    "    timeseries[ts] = df_ts\n",
    "(df_in, available_energy, storage_pmax, storage_SOC_max) = timeseries.values()\n",
    "\n",
    "# Group time series by dispatch window label\n",
    "for ts in timeseries.keys():\n",
    "    #print(ts)\n",
    "    df_ts = timeseries[ts]\n",
    "    df_ts = df_ts.groupby(df_in[\"label\"])\n",
    "    timeseries[ts] = df_ts\n",
    "(df_in, available_energy, storage_pmax, storage_SOC_max) = timeseries.values()\n",
    "\n",
    "# Loop through windows and storage resources; get initial SOC of each storage resource for each dispatch window\n",
    "df_initial_storage_SOC = pd.DataFrame(columns=durations.index)\n",
    "for window in available_energy.groups:\n",
    "    \n",
    "    # Get time series for dispatch window\n",
    "    df_in_window = df_in.get_group(window)\n",
    "    available_energy_window = available_energy.get_group(window)\n",
    "    storage_pmax_window = storage_pmax.get_group(window)\n",
    "    storage_SOC_max_window = storage_SOC_max.get_group(window)\n",
    "\n",
    "    # Get first timestep of dispatch window\n",
    "    window_start = df_in_window.index[df_in_window[\"in\"].shift(1) < df_in_window[\"in\"]]\n",
    "    assert len(window_start) == 1\n",
    "    window_start = window_start[0]\n",
    "    \n",
    "    # Charge resources in order of duration (shortest to longest)\n",
    "    for resource in durations.index:\n",
    "\n",
    "        # Calculate charging for resource\n",
    "        charging = storage_pmax_window[resource].clip(upper=available_energy_window)\n",
    "        SOC = charging.multiply(storage_data_dict[resource][\"charging_efficiency\"]).shift(1).fillna(0).cumsum().clip(upper=storage_SOC_max_window[resource])\n",
    "        charging_final = charging.clip(upper=storage_SOC_max_window[resource] - SOC)\n",
    "\n",
    "        # Update available energy\n",
    "        available_energy_window -= charging_final\n",
    "        \n",
    "        # Save initial SOC of storage resource\n",
    "        df_initial_storage_SOC.loc[window_start, resource] = SOC.loc[window_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_storage_SOC[\"hour\"] = timestamp_to_hour_mapping.loc[df_initial_storage_SOC.index]\n",
    "df_initial_storage_SOC = df_initial_storage_SOC.reset_index(drop=True).set_index([\"hour\"])\n",
    "df_initial_storage_SOC.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf41e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_storage_SOC.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9b6552-63ba-4c33-a7b4-79e59b7c60ae",
   "metadata": {},
   "source": [
    "## Identify Positive Net Load Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138285b2-5255-4e4f-81c9-35b3d41bffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321eba1-c0c1-4d4c-8a8e-69ca39255d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_positive_net_load_periods(series: pd.Series):\n",
    "    non_neg_series = series >= 0\n",
    "    non_neg_groups = (non_neg_series != non_neg_series.shift(1)).cumsum() * non_neg_series\n",
    "    starts_and_ends = non_neg_series.groupby(non_neg_groups).apply(lambda s: (s.index.get_level_values(\"timestamp\").min(), s.index.get_level_values(\"timestamp\").max()))\n",
    "    starts_and_ends = starts_and_ends.drop(0, axis=0).reset_index(drop=True).rename_axis(index=_PERIOD_ID)\n",
    "    starts_and_ends = pd.DataFrame(index=starts_and_ends.index, data=starts_and_ends.values.tolist(), columns=[_START_DATETIME_COLNAME, _END_DATETIME_COLNAME])\n",
    "    \n",
    "    return starts_and_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa701a-5660-42d0-8c60-2fb4bdb89427",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_and_end_times = input_data.groupby([\"MC_draw\", \"year\"]).apply(find_positive_net_load_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebed0d65-a83a-47c8-b13b-5f7d32b358ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_and_end_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe152995-6454-4ddc-9bfc-e6da4ea8d1d4",
   "metadata": {},
   "source": [
    "## Add Buffer Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fbd84d-f018-4528-840d-af3e44cdb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_and_end_times_with_buffer = start_and_end_times.copy()\n",
    "start_and_end_times_with_buffer.loc[:, _START_DATETIME_COLNAME] = (start_and_end_times_with_buffer.loc[:, _START_DATETIME_COLNAME] + _PERIOD_START_BUFFER).dt.floor(\"D\")\n",
    "start_and_end_times_with_buffer.loc[:, _END_DATETIME_COLNAME] = (start_and_end_times_with_buffer.loc[:, _END_DATETIME_COLNAME] + _PERIOD_END_BUFFER).dt.ceil(\"D\") - pd.Timedelta(hours=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680bb4e-4910-4bdd-926c-b7264ac2f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat({\"No Buffer\": start_and_end_times, \"With Buffer\": start_and_end_times_with_buffer}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ae9b98-4669-478a-8478-33ad960124c3",
   "metadata": {},
   "source": [
    "## Combine Overlapping Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d61ee6-087e-449c-8bf1-38297aa4d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_overlapping_windows(frame: pd.DataFrame):\n",
    "    start_date = frame.loc[:, _START_DATETIME_COLNAME].iloc[0]\n",
    "    end_date = frame.loc[:, _END_DATETIME_COLNAME].iloc[0]\n",
    "    period_id = 0\n",
    "    window_id = 0\n",
    "    \n",
    "    results = pd.DataFrame(index=pd.Index([period_id], name=_PERIOD_ID), columns=[_START_DATETIME_COLNAME, _END_DATETIME_COLNAME])\n",
    "    \n",
    "    for index, row in frame.iloc[1:, :].iterrows():\n",
    "        # print(\"curr start date: \", start_date)\n",
    "        # print(\"curr end date: \", end_date)\n",
    "        # print(\"period id: \", period_id )\n",
    "        # display(row)\n",
    "        if row[_START_DATETIME_COLNAME] < end_date:\n",
    "            end_date = row[_END_DATETIME_COLNAME]\n",
    "        else:\n",
    "            # display(period_id)\n",
    "            results.loc[period_id, _START_DATETIME_COLNAME] = start_date\n",
    "            results.loc[period_id, _END_DATETIME_COLNAME] = end_date\n",
    "            # results.loc[period_id, _DISPATCH_PROBLEM_ID] = window_id\n",
    "            period_id += 1\n",
    "            # if (row[_START_DATETIME_COLNAME] - _PERIOD_MIN_SEPARATION_WINDOW) > end_date:\n",
    "            #     window_id += 1\n",
    "                \n",
    "            start_date = row[_START_DATETIME_COLNAME]\n",
    "            end_date = row[_END_DATETIME_COLNAME]\n",
    "            # display(results)\n",
    "        # print()\n",
    "    \n",
    "    results.loc[period_id, _START_DATETIME_COLNAME] = start_date\n",
    "    results.loc[period_id, _END_DATETIME_COLNAME] = end_date\n",
    "    # results.loc[period_id, _DISPATCH_PROBLEM_ID] = window_id\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5f9a3-7c15-4348-a76e-e9235eae0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_start_and_ends = start_and_end_times_with_buffer.groupby([\"MC_draw\", \"year\"]).apply(combine_overlapping_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1096c8-e007-4c96-bfa9-c406bf95a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_start_and_ends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77824c5b-fd7e-4621-a6c5-a739c62c0352",
   "metadata": {},
   "source": [
    "## Find Start Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e84cb-abbe-4406-afe8-ee30107036c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dispatch_problem_start_timestamp(frame):\n",
    "    if frame[_END_DATETIME_COLNAME].min() > frame[_END_DATETIME_COLNAME].min().replace(month=1, day=1, hour=0) + _PERIOD_MIN_LEAD_WINDOW:\n",
    "        start_timestamp = frame[_END_DATETIME_COLNAME].min().replace(month=1, day=1, hour=0)\n",
    "    else:\n",
    "        start_timestamp = frame[_END_DATETIME_COLNAME].min() + pd.Timedelta(hours=1)\n",
    "    \n",
    "    return start_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c13e7f-18d8-48e0-8e17-7cab04594f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timestamps = grouped_start_and_ends.groupby([\"MC_draw\", \"year\"]).apply(find_dispatch_problem_start_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5088b978-414e-4f38-825d-833d58689d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c9b59-9f83-426b-9f7a-7ceb59f31027",
   "metadata": {},
   "source": [
    "## Ordering Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e1b0b1-4a42-4d16-ac0e-260378126533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timestamp_mapping(start_date):\n",
    "    index = pd.date_range(start=start_date, periods=8760, freq=\"H\")\n",
    "    series = pd.Series(index=index, data=list(range(len(index))))\n",
    "    series.index = series.index.map(lambda ts: ts.replace(year=start_date.year))\n",
    "    series = series.sort_index()\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b74a3-65f2-4feb-8288-b901ac695526",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_numbers = start_timestamps.apply(create_timestamp_mapping).T.rename_axis(index=\"timestamp\").stack([\"MC_draw\", \"year\"]).reorder_levels([\"MC_draw\", \"year\", \"timestamp\"]).rename(\"timestamp\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67099be5-ba96-4bc7-a9a7-9287a10c8e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([input_data, timestamp_numbers], axis=1).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5433f-40e3-4d0a-a671-7b69b0a9286b",
   "metadata": {},
   "source": [
    "# Comparing Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c7088-0965-44a5-b62f-6505b4f51885",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_start_and_ends.loc[:, \"problem_length\"] = (grouped_start_and_ends[\"end_datetime\"] - grouped_start_and_ends[\"start_datetime\"]) / pd.Timedelta(hours=1)\n",
    "grouped_start_and_ends = grouped_start_and_ends.astype({\"problem_length\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a8f4df-0f66-49f1-951e-64652bde379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_by_draw_and_year = grouped_start_and_ends.groupby([\"MC_draw\", \"year\"])[\"problem_length\"].agg([\"sum\", \"count\"]).astype(int).rename({\"sum\": \"Dispatch Hours per Year\", \"count\": \"Dispatch Events per Year\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903fd49-1aef-4d1f-9aa9-b3e9c9d68fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_by_draw_and_year.groupby(\"MC_draw\").describe().drop([\"count\", \"std\"], axis=1, level=1).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b767c-56c4-42db-b025-dbd2c71d233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series = pd.Series(index=[pd.Timestamp(\"1979-01-01 00:00\"), pd.Timestamp(\"2021-12-31 23:00\")], data=0)\n",
    "for idx, row in grouped_start_and_ends.xs(\"MC_draw_0\").iterrows():\n",
    "    plot_series.loc[row[_START_DATETIME_COLNAME]] = 1.0\n",
    "    plot_series.loc[row[_END_DATETIME_COLNAME]] = 0.0\n",
    "plot_series = plot_series.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6e2c9-0e5a-41d4-b299-37ca679b2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series_original  = pd.Series(index=[pd.Timestamp(\"1979-01-01 00:00\"), pd.Timestamp(\"2021-12-31 23:00\")], data=0)\n",
    "for idx, row in start_and_end_times.xs(\"MC_draw_0\").iterrows():\n",
    "    plot_series_original.loc[row[_START_DATETIME_COLNAME]] = 1.0\n",
    "    if row[_END_DATETIME_COLNAME] == row[_START_DATETIME_COLNAME]:\n",
    "        plot_series_original.loc[row[_END_DATETIME_COLNAME] + pd.Timedelta(hours=1)] = 0.0\n",
    "    else:\n",
    "        plot_series_original.loc[row[_END_DATETIME_COLNAME]] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff7025-5e7f-49da-9fc1-0a644e869b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49117b27-5842-461c-a6fb-61d17d21a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25957d6-1f3e-4150-b168-6575f067e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.FigureWidget()\n",
    "fig.add_scatter(\n",
    "    x=plot_series.index,\n",
    "    y=plot_series,\n",
    "    name=\"Dispatch Windows\",\n",
    "    line=dict(shape=\"hv\"),\n",
    "    fill=\"tozeroy\"\n",
    ")\n",
    "fig.add_scatter(\n",
    "    x=plot_series_original.index,\n",
    "    y=plot_series_original,\n",
    "    name=\"Positive Net Load Periods\",\n",
    "    line=dict(shape=\"hv\"),\n",
    "    fill=\"tozeroy\"\n",
    ")\n",
    "fig.update_layout(height=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fead92c-ce1b-44f0-9bd8-8c8e46029ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.update_xaxes(range=[\"1984-01-01\", \"1986-01-01\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87384a83-7ea1-420c-8f46-43e5b589c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.update_xaxes(range=[\"1984-06-10\", \"1984-07-25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07974a18-9084-424e-8470-98a5cb5f3e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
